**ASL - American Sign Language Recognition**
An AI-powered application that recognizes American Sign Language gestures using computer vision and machine learning.

**Overview**
ASL is a deep learning-based project developed to assist communication for the hearing and speech impaired. The system captures hand gestures via webcam and predicts the corresponding alphabet or word using a trained Convolutional Neural Network (CNN). The application is designed for real-time usage and is structured to be scalable and modular.

**Features**
â€¢ Real-time gesture detection using webcam
â€¢ Model training on a custom ASL dataset
â€¢ Prediction and live classification of ASL letters
â€¢ Data preprocessing and augmentation support
â€¢ User-friendly interface for demo and testing
â€¢ Modular codebase with separate scripts for capture, training, prediction

**Tech Stack**
Language: Python
Libraries: OpenCV, NumPy, TensorFlow/Keras, Pandas
Model: CNN (Convolutional Neural Network)
IDE: VS Code / Jupyter
Others: Matplotlib, Scikit-learn

**Installation**
Clone the repository:

Create and activate a virtual environment (optional):
python -m venv venv  
source venv/bin/activate  # for Linux/macOS  
venv\Scripts\activate     # for Windows 
 
**Install dependencies:**
pip install -r requirements.txt

**Project Structure**

ASL-Recognition/


â”‚
â”œâ”€â”€ data/               # Dataset containing train/test images
â”‚   â”œâ”€â”€ train/          
â”‚   â””â”€â”€ test/
â”‚
â”œâ”€â”€ model/              # Trained model weights (saved .h5 file)
â”‚
â”œâ”€â”€ src/                
â”‚   â”œâ”€â”€ capture.py     
â”‚   â”œâ”€â”€ train.py       
â”‚   â”œâ”€â”€ predict.py     
â”‚   â””â”€â”€ utils.py       
â”‚
â”œâ”€â”€ README.md           
â”œâ”€â”€ requirements.txt   
â””â”€â”€ .gitignore          


ğŸ¤ **Contributions**
Feel free to fork and raise a pull request! Contributions are welcome.
For major changes, please open an issue first to discuss what you would like to change.

